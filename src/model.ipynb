{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get('https://api.data.gov.sg/v1/transport/traffic-images')\n",
    "results = json.loads(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = results['items'][0]['cameras']\n",
    "\n",
    "# Flatten the nested dictionary structure\n",
    "camera_data = []\n",
    "for camera in cameras:\n",
    "    camera_info = {\n",
    "        'timestamp': camera['timestamp'],\n",
    "        'image': camera['image'],\n",
    "        'latitude': camera['location']['latitude'],\n",
    "        'longitude': camera['location']['longitude'],\n",
    "        'camera_id': camera['camera_id'],\n",
    "        'image_height': camera['image_metadata']['height'],\n",
    "        'image_width': camera['image_metadata']['width'],\n",
    "        'image_md5': camera['image_metadata']['md5']\n",
    "    }\n",
    "    camera_data.append(camera_info)\n",
    "\n",
    "# Create a DataFrame from the flattened data\n",
    "df = pd.DataFrame(camera_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "2.3.1+cu118\n"
     ]
    }
   ],
   "source": [
    "## Hugging face api\n",
    "images = df['image'].tolist()\n",
    "response = requests.get(images[1])\n",
    "\n",
    "image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "\n",
    "checkpoint = \"google/owlv2-base-patch16-ensemble\"\n",
    "detector = pipeline(model=checkpoint, task=\"zero-shot-object-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction [{'score': 0.34078532457351685, 'label': 'cars', 'box': {'xmin': 23, 'ymin': 159, 'xmax': 50, 'ymax': 193}}, {'score': 0.3350667953491211, 'label': 'cars', 'box': {'xmin': 62, 'ymin': 160, 'xmax': 92, 'ymax': 196}}, {'score': 0.3174554109573364, 'label': 'cars', 'box': {'xmin': 12, 'ymin': 95, 'xmax': 28, 'ymax': 112}}, {'score': 0.2799484133720398, 'label': 'cars', 'box': {'xmin': 44, 'ymin': 111, 'xmax': 64, 'ymax': 133}}, {'score': 0.27133414149284363, 'label': 'cars', 'box': {'xmin': 33, 'ymin': 89, 'xmax': 46, 'ymax': 103}}, {'score': 0.1744813323020935, 'label': 'cars', 'box': {'xmin': 12, 'ymin': 87, 'xmax': 46, 'ymax': 114}}, {'score': 0.1457502245903015, 'label': 'cars', 'box': {'xmin': 22, 'ymin': 149, 'xmax': 93, 'ymax': 198}}, {'score': 0.13766515254974365, 'label': 'cars', 'box': {'xmin': 12, 'ymin': 87, 'xmax': 49, 'ymax': 143}}, {'score': 0.11406024545431137, 'label': 'cars', 'box': {'xmin': 11, 'ymin': 87, 'xmax': 30, 'ymax': 113}}, {'score': 0.1024443581700325, 'label': 'cars', 'box': {'xmin': 63, 'ymin': 166, 'xmax': 92, 'ymax': 197}}, {'score': 0.1001984104514122, 'label': 'cars', 'box': {'xmin': 65, 'ymin': 152, 'xmax': 92, 'ymax': 168}}]\n"
     ]
    }
   ],
   "source": [
    "prediction = detector(image, candidate_labels=['cars'])\n",
    "print('prediction', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "for p in prediction:\n",
    "    box = p['box']  \n",
    "    label = p['label']\n",
    "    score = p['score']\n",
    "\n",
    "    xmin, ymin, xmax, ymax = box.values()\n",
    "    draw.rectangle((xmin, ymin, xmax, ymax), outline='red', width=1)\n",
    "    draw.text((xmin, ymin), f'{label}: {round(score, 2)}', fill='white')\n",
    "\n",
    "image_filename = 'annotated_image.jpg'\n",
    "image.save(image_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "# import requests\n",
    "\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# @app.route('/congestion', methods=['POST'])\n",
    "# def get_congestion_data():\n",
    "#     data = request.json\n",
    "#     lon, lat = data['longitude'], data['latitude']\n",
    "    \n",
    "#     # Call data.gov.sg API\n",
    "#     traffic_data = requests.get('https://api.data.gov.sg/v1/transport/traffic-images').json()\n",
    "#     image_url = get_image_url(traffic_data, lon, lat)  # Implement this function to get relevant image URL\n",
    "\n",
    "#     # Call AI Model for car count\n",
    "#     car_count = call_ai_model(image_url)  # Implement this function to use OpenAI/HuggingFace API\n",
    "    \n",
    "#     # Determine congestion level\n",
    "#     congestion_level = categorize_congestion(car_count)  # Implement this function to categorize\n",
    "    \n",
    "#     # Call Location API for address\n",
    "#     location = get_location(lon, lat)  # Implement this function to call reverse geocoding API\n",
    "    \n",
    "#     return jsonify({\n",
    "#         'car_count': car_count,\n",
    "#         'congestion_level': congestion_level,\n",
    "#         'location': location\n",
    "#     })\n",
    "\n",
    "# def get_image_url(traffic_data, lon, lat):\n",
    "#     # Logic to find the closest traffic camera image based on lon/lat\n",
    "#     pass\n",
    "\n",
    "# def call_ai_model(image_url):\n",
    "#     # Logic to send image to AI model and get car count\n",
    "#     pass\n",
    "\n",
    "# def categorize_congestion(car_count):\n",
    "#     if car_count < 10:\n",
    "#         return 1\n",
    "#     elif car_count < 20:\n",
    "#         return 2\n",
    "#     elif car_count < 30:\n",
    "#         return 3\n",
    "#     else:\n",
    "#         return 4\n",
    "\n",
    "# def get_location(lon, lat):\n",
    "#     response = requests.get(f'https://api.location.service/reverse-geocode?lon={lon}&lat={lat}')\n",
    "#     return response.json()['location']\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

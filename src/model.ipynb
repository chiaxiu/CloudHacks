{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pipeline' from 'transformers' (c:\\Users\\vanne\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageDraw\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BytesIO\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'pipeline' from 'transformers' (c:\\Users\\vanne\\anaconda3\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get('https://api.data.gov.sg/v1/transport/traffic-images')\n",
    "results = json.loads(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cameras = results['items'][0]['cameras']\n",
    "\n",
    "# Flatten the nested dictionary structure\n",
    "camera_data = []\n",
    "for camera in cameras:\n",
    "    camera_info = {\n",
    "        'timestamp': camera['timestamp'],\n",
    "        'image': camera['image'],\n",
    "        'latitude': camera['location']['latitude'],\n",
    "        'longitude': camera['location']['longitude'],\n",
    "        'camera_id': camera['camera_id'],\n",
    "        'image_height': camera['image_metadata']['height'],\n",
    "        'image_width': camera['image_metadata']['width'],\n",
    "        'image_md5': camera['image_metadata']['md5']\n",
    "    }\n",
    "    camera_data.append(camera_info)\n",
    "\n",
    "# Create a DataFrame from the flattened data\n",
    "df = pd.DataFrame(camera_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hugging face api\n",
    "images = df['image'].tolist()\n",
    "response = requests.get(images[1])\n",
    "\n",
    "image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "\n",
    "checkpoint = \"google/owlv2-base-patch16-ensemble\"\n",
    "detector = pipeline(model=checkpoint, task=\"zero-shot-object-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = detector(image, candidate_labels=['cars'])\n",
    "print('prediction', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_verified_cars(image):\n",
    "    verified_cars = 0\n",
    "    for car in image:\n",
    "        if car['score'] > 0.12:\n",
    "            verified_cars += 1\n",
    "    return verified_cars\n",
    "\n",
    "verified_cars = count_verified_cars(prediction)\n",
    "print(verified_cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "for p in prediction:\n",
    "    box = p['box']  \n",
    "    label = p['label']\n",
    "    score = p['score']\n",
    "\n",
    "    xmin, ymin, xmax, ymax = box.values()\n",
    "    draw.rectangle((xmin, ymin, xmax, ymax), outline='red', width=1)\n",
    "    draw.text((xmin, ymin), f'{label}: {round(score, 2)}', fill='white')\n",
    "\n",
    "image_filename = 'annotated_image.jpg'\n",
    "image.save(image_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, jsonify\n",
    "# import requests\n",
    "\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# @app.route('/congestion', methods=['POST'])\n",
    "# def get_congestion_data():\n",
    "#     data = request.json\n",
    "#     lon, lat = data['longitude'], data['latitude']\n",
    "    \n",
    "#     # Call data.gov.sg API\n",
    "#     traffic_data = requests.get('https://api.data.gov.sg/v1/transport/traffic-images').json()\n",
    "#     image_url = get_image_url(traffic_data, lon, lat)  # Implement this function to get relevant image URL\n",
    "\n",
    "#     # Call AI Model for car count\n",
    "#     car_count = call_ai_model(image_url)  # Implement this function to use OpenAI/HuggingFace API\n",
    "    \n",
    "#     # Determine congestion level\n",
    "#     congestion_level = categorize_congestion(car_count)  # Implement this function to categorize\n",
    "    \n",
    "#     # Call Location API for address\n",
    "#     location = get_location(lon, lat)  # Implement this function to call reverse geocoding API\n",
    "    \n",
    "#     return jsonify({\n",
    "#         'car_count': car_count,\n",
    "#         'congestion_level': congestion_level,\n",
    "#         'location': location\n",
    "#     })\n",
    "\n",
    "# def get_image_url(traffic_data, lon, lat):\n",
    "#     # Logic to find the closest traffic camera image based on lon/lat\n",
    "#     pass\n",
    "\n",
    "# def call_ai_model(image_url):\n",
    "#     # Logic to send image to AI model and get car count\n",
    "#     pass\n",
    "\n",
    "# def categorize_congestion(car_count):\n",
    "#     if car_count < 10:\n",
    "#         return 1\n",
    "#     elif car_count < 20:\n",
    "#         return 2\n",
    "#     elif car_count < 30:\n",
    "#         return 3\n",
    "#     else:\n",
    "#         return 4\n",
    "\n",
    "# def get_location(lon, lat):\n",
    "#     response = requests.get(f'https://api.location.service/reverse-geocode?lon={lon}&lat={lat}')\n",
    "#     return response.json()['location']\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get('https://api.data.gov.sg/v1/transport/traffic-images')\n",
    "results = json.loads(data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hugging face api\n",
    "images = df['image'].tolist()\n",
    "response = requests.get(images[1])\n",
    "\n",
    "image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "\n",
    "checkpoint = \"google/owlv2-base-patch16-ensemble\"\n",
    "detector = pipeline(model=checkpoint, task=\"zero-shot-object-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDraw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m draw \u001b[38;5;241m=\u001b[39m \u001b[43mImageDraw\u001b[49m\u001b[38;5;241m.\u001b[39mDraw(image)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prediction:\n\u001b[0;32m      4\u001b[0m     box \u001b[38;5;241m=\u001b[39m p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m'\u001b[39m]  \n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDraw' is not defined"
     ]
    }
   ],
   "source": [
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "for p in prediction:\n",
    "    box = p['box']  \n",
    "    label = p['label']\n",
    "    score = p['score']\n",
    "\n",
    "    xmin, ymin, xmax, ymax = box.values()\n",
    "    draw.rectangle((xmin, ymin, xmax, ymax), outline='red', width=1)\n",
    "    draw.text((xmin, ymin), f'{label}: {round(score, 2)}', fill='white')\n",
    "\n",
    "image_filename = 'annotated_image.jpg'\n",
    "image.save(image_filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
